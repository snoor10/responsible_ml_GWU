{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "####License\n",
        "Copyright 2023 Sadman Noor (snoor11@gwmail.gwu.edu)\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
        "\n",
        "http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
        "\n",
        "DISCLAIMER: This notebook is not legal or compliance advice."
      ],
      "metadata": {
        "id": "Ln5JM1en77Dx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 3"
      ],
      "metadata": {
        "id": "o_b7K8Ib8LLY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports and inits"
      ],
      "metadata": {
        "id": "njEtt4xw8QS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "from google.colab import files  "
      ],
      "metadata": {
        "id": "J8faCo2t84me"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "ZXMoc2CrNh8E"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h2o"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMXgubiXAhbd",
        "outputId": "0d58d5e8-ba48-4ebd-afab-7281902b637a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting h2o\n",
            "  Downloading h2o-3.40.0.4.tar.gz (177.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from h2o) (2.27.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from h2o) (0.8.10)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from h2o) (0.18.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->h2o) (3.4)\n",
            "Building wheels for collected packages: h2o\n",
            "  Building wheel for h2o (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for h2o: filename=h2o-3.40.0.4-py2.py3-none-any.whl size=177697886 sha256=8d6984e682149989b3fc27e324790f7a5610e818bf677c8a0c5e01c84adbc1ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/f2/b0/5bb4d702a0467e82d77c45088db3eef25114c26b0eec8e7f6a\n",
            "Successfully built h2o\n",
            "Installing collected packages: h2o\n",
            "Successfully installed h2o-3.40.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install interpret"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apGk3SaeAmIo",
        "outputId": "26375cdb-ef24-4b67-eb18-ce365bce9ecb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting interpret\n",
            "  Downloading interpret-0.4.2-py3-none-any.whl (1.4 kB)\n",
            "Collecting interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2 (from interpret)\n",
            "  Downloading interpret_core-0.4.2-py3-none-any.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lime>=0.1.1.33 (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret)\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: plotly>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (5.13.1)\n",
            "Requirement already satisfied: numpy<1.24.0,>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (1.10.1)\n",
            "Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.10/dist-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (1.2.0)\n",
            "Collecting SALib>=1.3.3 (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret)\n",
            "  Downloading salib-1.4.7-py3-none-any.whl (757 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m758.0/758.0 kB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting shap>=0.28.5 (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret)\n",
            "  Downloading shap-0.41.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (572 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.6/572.6 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill>=0.2.5 (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting treeinterpreter>=0.2.2 (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret)\n",
            "  Downloading treeinterpreter-0.2.3-py2.py3-none-any.whl (6.0 kB)\n",
            "Collecting skope-rules>=1.0.1 (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret)\n",
            "  Downloading skope_rules-1.0.1-py3-none-any.whl (14 kB)\n",
            "Collecting dash>=1.0.0 (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret)\n",
            "  Downloading dash-2.10.2-py3-none-any.whl (10.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dash-core-components>=1.0.0 (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret)\n",
            "  Downloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
            "Collecting dash-html-components>=1.0.0 (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret)\n",
            "  Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
            "Collecting dash-table>=4.1.0 (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret)\n",
            "  Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
            "Collecting dash-cytoscape>=0.1.1 (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret)\n",
            "  Downloading dash_cytoscape-0.3.0-py3-none-any.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gevent>=1.3.6 (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret)\n",
            "  Downloading gevent-22.10.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (2.27.1)\n",
            "Requirement already satisfied: psutil>=5.6.2 in /usr/local/lib/python3.10/dist-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (5.9.5)\n",
            "Requirement already satisfied: ipykernel>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (5.5.6)\n",
            "Requirement already satisfied: ipython>=5.5.0 in /usr/local/lib/python3.10/dist-packages (from interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (7.34.0)\n",
            "Requirement already satisfied: Flask<2.3.0,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash>=1.0.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (2.2.4)\n",
            "Collecting Werkzeug<2.3.0 (from dash>=1.0.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret)\n",
            "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zope.event (from gevent>=1.3.6->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret)\n",
            "  Downloading zope.event-4.6-py2.py3-none-any.whl (6.8 kB)\n",
            "Collecting zope.interface (from gevent>=1.3.6->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret)\n",
            "  Downloading zope.interface-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (246 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from gevent>=1.3.6->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (67.7.2)\n",
            "Requirement already satisfied: greenlet>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gevent>=1.3.6->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (2.0.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.10.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.10.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.10.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.10.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (6.3.1)\n",
            "Collecting jedi>=0.16 (from ipython>=5.5.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret)\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (3.0.38)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (2.14.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (4.8.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lime>=0.1.1.33->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (3.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lime>=0.1.1.33->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (4.65.0)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.10/dist-packages (from lime>=0.1.1.33->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (0.19.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19.2->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19.2->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (2022.7.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=3.8.1->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (8.2.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (3.4)\n",
            "Collecting multiprocess (from SALib>=1.3.3->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.1->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (3.1.0)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap>=0.28.5->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (23.1)\n",
            "Collecting slicer==0.0.7 (from shap>=0.28.5->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret)\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap>=0.28.5->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (0.56.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap>=0.28.5->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (2.2.1)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask<2.3.0,>=1.0.4->dash>=1.0.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<2.3.0,>=1.0.4->dash>=1.0.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask<2.3.0,>=1.0.4->dash>=1.0.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (8.1.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.5.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (0.8.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime>=0.1.1.33->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime>=0.1.1.33->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime>=0.1.1.33->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime>=0.1.1.33->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime>=0.1.1.33->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime>=0.1.1.33->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (3.0.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.5.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.5.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (0.2.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.19.2->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (1.16.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime>=0.1.1.33->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (3.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime>=0.1.1.33->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime>=0.1.1.33->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime>=0.1.1.33->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (1.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from Werkzeug<2.3.0->dash>=1.0.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (2.1.2)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel>=4.10.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (5.3.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel>=4.10.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (23.2.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap>=0.28.5->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (0.39.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel>=4.10.0->interpret-core[dash,debug,decisiontree,ebm,lime,linear,notebook,plotly,required,sensitivity,shap,skoperules,treeinterpreter]==0.4.2->interpret) (3.3.0)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283839 sha256=615b6e197e0862c478764b457672383f86a7b02fc5d766a491cb8fb55e3aea70\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/a2/af/9ac0a1a85a27f314a06b39e1f492bee1547d52549a4606ed89\n",
            "Successfully built lime\n",
            "Installing collected packages: treeinterpreter, interpret-core, dash-table, dash-html-components, dash-core-components, zope.interface, zope.event, Werkzeug, slicer, jedi, dill, multiprocess, gevent, skope-rules, shap, SALib, lime, dash, dash-cytoscape, interpret\n",
            "  Attempting uninstall: Werkzeug\n",
            "    Found existing installation: Werkzeug 2.3.0\n",
            "    Uninstalling Werkzeug-2.3.0:\n",
            "      Successfully uninstalled Werkzeug-2.3.0\n",
            "Successfully installed SALib-1.4.7 Werkzeug-2.2.3 dash-2.10.2 dash-core-components-2.0.0 dash-cytoscape-0.3.0 dash-html-components-2.0.0 dash-table-5.0.0 dill-0.3.6 gevent-22.10.2 interpret-0.4.2 interpret-core-0.4.2 jedi-0.18.2 lime-0.2.0.1 multiprocess-0.70.14 shap-0.41.0 skope-rules-1.0.1 slicer-0.0.7 treeinterpreter-0.2.3 zope.event-4.6 zope.interface-6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from interpret.glassbox import ExplainableBoostingClassifier  # interpret ebm class\n",
        "from interpret.perf import ROC                                # ROC measure for ebm\n",
        "import itertools                                              # for cartesian product of parameters\n",
        "import matplotlib.pyplot as plt                               # for plots\n",
        "import numpy as np                                            # for basic array manipulation                            \n",
        "import pandas as pd                                           # for dataframe manipulation\n",
        "import random                                                 # to sample from lists\n",
        "from sklearn.metrics import accuracy_score, f1_score          # for selecting model cutoffs\n",
        "import time                                                   # for timers\n",
        "\n",
        "# set numpy random seed for better reproducibility\n",
        "SEED = 12345 \n",
        "np.random.seed(SEED)\n",
        "\n",
        "# set number of threads\n",
        "NTHREAD = 4"
      ],
      "metadata": {
        "id": "5Vr5EhkFAxqW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define Utility Functions "
      ],
      "metadata": {
        "id": "HMYwfaGCA2TC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Utility function to calculate confusion matrices by demographic group"
      ],
      "metadata": {
        "id": "mkdvWmHXA6UZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_confusion_matrix(frame, y, yhat, by=None, level=None, cutoff=0.5, verbose=True):\n",
        "\n",
        "    \"\"\" Creates confusion matrix from pandas dataframe of y and yhat values, can be sliced \n",
        "        by a variable and level.\n",
        "    \n",
        "        :param frame: Pandas dataframe of actual (y) and predicted (yhat) values.\n",
        "        :param y: Name of actual value column.\n",
        "        :param yhat: Name of predicted value column.\n",
        "        :param by: By variable to slice frame before creating confusion matrix, default None.\n",
        "        :param level: Value of by variable to slice frame before creating confusion matrix, default None.\n",
        "        :param cutoff: Cutoff threshold for confusion matrix, default 0.5. \n",
        "        :param verbose: Whether to print confusion matrix titles, default True. \n",
        "        :return: Confusion matrix as pandas dataframe. \n",
        "        \n",
        "    \"\"\"\n",
        "    \n",
        "    # determine levels of target (y) variable\n",
        "    # sort for consistency\n",
        "    level_list = list(frame[y].unique())\n",
        "    level_list.sort(reverse=True) \n",
        "\n",
        "    # init confusion matrix\n",
        "    cm_frame = pd.DataFrame(columns=['actual: ' +  str(i) for i in level_list], \n",
        "                            index=['predicted: ' + str(i) for i in level_list])\n",
        "    \n",
        "    # don't destroy original data\n",
        "    frame_ = frame.copy(deep=True)\n",
        "    \n",
        "    # convert numeric predictions to binary decisions using cutoff\n",
        "    dname = 'd_' + str(y)\n",
        "    frame_[dname] = np.where(frame_[yhat] > cutoff , 1, 0)\n",
        "    \n",
        "    # slice frame\n",
        "    if (by is not None) & (level is not None):\n",
        "        frame_ = frame_[frame[by] == level]\n",
        "    \n",
        "    # calculate size of each confusion matrix value\n",
        "    for i, lev_i in enumerate(level_list):\n",
        "        for j, lev_j in enumerate(level_list):\n",
        "            cm_frame.iat[j, i] = frame_[(frame_[y] == lev_i) & (frame_[dname] == lev_j)].shape[0]\n",
        "            # i, j vs. j, i nasty little bug ... updated 8/30/19\n",
        "    \n",
        "    # output results\n",
        "    if verbose:\n",
        "        if by is None:\n",
        "            print('Confusion matrix:')\n",
        "        else:\n",
        "            print('Confusion matrix by ' + by + '=' + str(level))\n",
        "    \n",
        "    return cm_frame"
      ],
      "metadata": {
        "id": "GhyeqCjrA84a"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Utility function to calculate AIR"
      ],
      "metadata": {
        "id": "I-K12mhFBB8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def air(cm_dict, reference_key, protected_key, verbose=True):\n",
        "\n",
        "    \"\"\" Calculates the adverse impact ratio as a quotient between protected and \n",
        "        reference group acceptance rates: protected_prop/reference_prop. \n",
        "        Optionally prints intermediate values. ASSUMES 0 IS \"POSITIVE\" OUTCOME!\n",
        "\n",
        "        :param cm_dict: Dictionary of demographic group confusion matrices. \n",
        "        :param reference_key: Name of reference group in cm_dict as a string.\n",
        "        :param protected_key: Name of protected group in cm_dict as a string.\n",
        "        :param verbose: Whether to print intermediate acceptance rates, default True. \n",
        "        :return: AIR.\n",
        "        \n",
        "    \"\"\"\n",
        "\n",
        "    eps = 1e-20 # numeric stability and divide by 0 protection\n",
        "    \n",
        "    # reference group summary\n",
        "    reference_accepted = float(cm_dict[reference_key].iat[1,0] + cm_dict[reference_key].iat[1,1]) # predicted 0's\n",
        "    reference_total = float(cm_dict[reference_key].sum().sum())\n",
        "    reference_prop = reference_accepted/reference_total\n",
        "    if verbose:\n",
        "        print(reference_key.title() + ' proportion accepted: %.3f' % reference_prop)\n",
        "    \n",
        "    # protected group summary\n",
        "    protected_accepted = float(cm_dict[protected_key].iat[1,0] + cm_dict[protected_key].iat[1,1]) # predicted 0's\n",
        "    protected_total = float(cm_dict[protected_key].sum().sum())\n",
        "    protected_prop = protected_accepted/protected_total\n",
        "    if verbose:\n",
        "        print(protected_key.title() + ' proportion accepted: %.3f' % protected_prop)\n",
        "\n",
        "    # return adverse impact ratio\n",
        "    return ((protected_prop + eps)/(reference_prop + eps))"
      ],
      "metadata": {
        "id": "cp5wDyqEBDOX"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Utility function to select probability cutoff by F1"
      ],
      "metadata": {
        "id": "bvsPcUNuBHFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_max_f1_frame(frame, y, yhat, res=0.01, air_reference=None, air_protected=None): \n",
        "    \n",
        "    \"\"\" Utility function for finding max. F1. \n",
        "        Coupled to get_confusion_matrix() and air(). \n",
        "        Assumes 1 is the marker for class membership.\n",
        "    \n",
        "        :param frame: Pandas dataframe of actual (y) and predicted (yhat) values.\n",
        "        :param y: Known y values.\n",
        "        :param yhat: Model scores.\n",
        "        :param res: Resolution over which to search for max. F1, default 0.01.\n",
        "        :param air_reference: Reference group for AIR calculation, optional.\n",
        "        :param air_protected: Protected group for AIR calculation, optional.\n",
        "        :return: Pandas DataFrame of cutoffs to select from.\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    do_air = all(v is not None for v in [air_reference, air_protected])\n",
        "    \n",
        "    # init frame to store f1 at different cutoffs\n",
        "    if do_air:\n",
        "        columns = ['cut', 'f1', 'acc', 'air']\n",
        "    else:\n",
        "        columns = ['cut', 'f1', 'acc']\n",
        "    f1_frame = pd.DataFrame(columns=['cut', 'f1', 'acc'])\n",
        "    \n",
        "    # copy known y and score values into a temporary frame\n",
        "    temp_df = frame[[y, yhat]].copy(deep=True)\n",
        "    \n",
        "    # find f1 at different cutoffs and store in acc_frame\n",
        "    for cut in np.arange(0, 1 + res, res):\n",
        "        temp_df['decision'] = np.where(temp_df.iloc[:, 1] > cut, 1, 0)\n",
        "        f1 = f1_score(temp_df.iloc[:, 0], temp_df['decision'])\n",
        "        acc = accuracy_score(temp_df.iloc[:, 0], temp_df['decision'])\n",
        "        row_dict = {'cut': cut, 'f1': f1, 'acc': acc}\n",
        "        if do_air:\n",
        "            # conditionally calculate AIR  \n",
        "            cm_ref = get_confusion_matrix(frame, y, yhat, by=air_reference, level=1, cutoff=cut, verbose=False)\n",
        "            cm_pro = get_confusion_matrix(frame, y, yhat, by=air_protected, level=1, cutoff=cut, verbose=False)\n",
        "            air_ = air({air_reference: cm_ref, air_protected: cm_pro}, air_reference, air_protected, verbose=False)\n",
        "            row_dict['air'] = air_\n",
        "            \n",
        "        f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
        "            \n",
        "    del temp_df\n",
        "        \n",
        "    return f1_frame    "
      ],
      "metadata": {
        "id": "YGb2JsyNBJQt"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Utility function for random grid search"
      ],
      "metadata": {
        "id": "9ndZPH92BNSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ebm_grid(train, valid, x_names, y_name, gs_params=None, n_models=None, early_stopping_rounds=None, seed=None,\n",
        "             air_reference=None, air_protected=None, air_cut=None):\n",
        "    \n",
        "    \"\"\" Performs a random grid search over n_models and gs_params.\n",
        "        Optionally considers random feature sets and AIR.\n",
        "        Coupled to get_confusion_matrix() and air(). \n",
        "\n",
        "    :param train: Training data as Pandas DataFrame.\n",
        "    :param valid: Validation data as Pandas DataFrame.\n",
        "    :param x_names: Names of input features.\n",
        "    :param y_name: Name of target feature.\n",
        "    :param gs_params: Dictionary of lists of potential EBM parameters over which to search.   \n",
        "    :param n_models: Number of random models to evaluate.\n",
        "    :param early_stopping_rounds: EBM early stopping rounds.\n",
        "    :param seed: Random seed for better interpretability.\n",
        "    :param air_reference: Reference group for AIR calculation, optional.\n",
        "    :param air_protected: Protected group for AIR calculation, optional.  \n",
        "    :param air_cut: Cutoff for AIR calculation, optional.\n",
        "    :return: Tuple: (Best EBM model, Pandas DataFrame of models to select from)\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    # init returned frame\n",
        "    do_air = all(v is not None for v in [air_reference, air_protected])\n",
        "    if do_air: \n",
        "        columns = list(gs_params.keys()) + ['features', 'auc', 'air']\n",
        "    else:\n",
        "        columns = list(gs_params.keys()) + ['auc']\n",
        "    ebm_grid_frame = pd.DataFrame(columns=columns)\n",
        "    \n",
        "    # cartesian product of gs_params\n",
        "    keys, values = zip(*gs_params.items())\n",
        "    experiments = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
        "\n",
        "    # preserve exact reproducibility for this function\n",
        "    np.random.seed(SEED) \n",
        "    \n",
        "    # select randomly from cartesian product space\n",
        "    selected_experiments = np.random.choice(len(experiments), n_models)\n",
        "\n",
        "    # set global params for seed, etc.\n",
        "    params = {'n_jobs': NTHREAD,\n",
        "              'early_stopping_rounds': early_stopping_rounds, \n",
        "              'random_state': SEED}\n",
        "\n",
        "    # init grid search loop\n",
        "    best_candidate = None\n",
        "    best_score = 0\n",
        "\n",
        "    # grid search loop\n",
        "    for i, exp in enumerate(selected_experiments):\n",
        "\n",
        "        params.update(experiments[exp])  # override global params with current grid run params\n",
        "\n",
        "        print('Grid search run %d/%d:' % (int(i + 1), int(n_models)))\n",
        "        print('Training with parameters:', params)\n",
        "        \n",
        "        # train \n",
        "        ebm = ExplainableBoostingClassifier(**params)\n",
        "        \n",
        "        # conditionally select random features \n",
        "        features = x_names\n",
        "        if do_air:\n",
        "            n_features = random.randrange(len(x_names)) + 1\n",
        "            features = random.sample(x_names, n_features)\n",
        "        candidate = ebm.fit(train[features], train[y_name]) \n",
        "\n",
        "        # calculate AUC\n",
        "        ebm_perf = ROC(ebm.predict_proba).explain_perf(valid[features], valid[y_name])\n",
        "        candidate_best_score = ebm_perf._internal_obj['overall']['auc']\n",
        "    \n",
        "        # compose values to add to ebm_grid_frame\n",
        "        row_dict = params.copy()\n",
        "        row_dict['auc'] = candidate_best_score\n",
        "        if do_air:\n",
        "            # collect random feature set\n",
        "            row_dict['features'] = features\n",
        "            # conditionally calculate AIR  \n",
        "            valid_phat = valid.copy(deep=True)\n",
        "            valid_phat['phat'] = candidate.predict_proba(valid[features])[:, 1]\n",
        "            cm_ref = get_confusion_matrix(valid_phat, y_name, 'phat', by=air_reference, level=1, cutoff=air_cut, verbose=False)\n",
        "            cm_pro = get_confusion_matrix(valid_phat, y_name, 'phat', by=air_protected, level=1, cutoff=air_cut, verbose=False)\n",
        "            air_ = air({air_reference: cm_ref, air_protected: cm_pro}, air_reference, air_protected, verbose=False)\n",
        "            row_dict['air'] = air_\n",
        "            del valid_phat\n",
        "\n",
        "        # append run to ebm_grid_frame\n",
        "        ebm_grid_frame = ebm_grid_frame.append(row_dict, ignore_index=True)\n",
        "    \n",
        "        # determine if current model is better than previous best\n",
        "        if candidate_best_score > best_score:\n",
        "            best_score = candidate_best_score\n",
        "            best_ebm = candidate\n",
        "            print('Grid search new best score discovered at iteration %d/%d: %.4f.' %\n",
        "                             (int(i + 1), int(n_models), candidate_best_score))\n",
        "\n",
        "        print('---------- ----------')\n",
        "        \n",
        "        del row_dict\n",
        "        del ebm\n",
        "            \n",
        "    return best_ebm, ebm_grid_frame"
      ],
      "metadata": {
        "id": "-MOpGgILBShz"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Start global timer"
      ],
      "metadata": {
        "id": "jAdioYwsBVTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tic = time.time()"
      ],
      "metadata": {
        "id": "b8tawgbZBYo-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import data"
      ],
      "metadata": {
        "id": "fvLx4OFUBafX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "-U-unYIJBcwz",
        "outputId": "8f60d0ca-e4be-4b10-ccf1-0e2da4db9386"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-591d5b9c-5d11-4559-b103-980407da4467\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-591d5b9c-5d11-4559-b103-980407da4467\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving hmda_test_preprocessed.csv to hmda_test_preprocessed.csv\n",
            "Saving hmda_train_preprocessed.csv to hmda_train_preprocessed.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('hmda_train_preprocessed.csv')\n",
        "test = pd.read_csv('hmda_test_preprocessed.csv')"
      ],
      "metadata": {
        "id": "e7lt4nyoCOTu"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Assign basic modeling roles"
      ],
      "metadata": {
        "id": "f5JY54DaCRcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_name = 'high_priced'\n",
        "x_names = ['term_360', 'conforming', 'debt_to_income_ratio_missing', 'loan_amount_std', 'loan_to_value_ratio_std', 'no_intro_rate_period_std',\n",
        "           'intro_rate_period_std', 'property_value_std', 'income_std', 'debt_to_income_ratio_std']"
      ],
      "metadata": {
        "id": "KUi9a2EQCT9x"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit interpretable model"
      ],
      "metadata": {
        "id": "9dyVyjGMCV7J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Split data into train and validation partitions"
      ],
      "metadata": {
        "id": "nL41cleoCYQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(SEED) # preserve exact reproducibility for this cell\n",
        "\n",
        "split_ratio = 0.7 # 70%/30% train/test split\n",
        "\n",
        "# execute split\n",
        "split = np.random.rand(len(data)) < split_ratio\n",
        "train = data[split]\n",
        "valid = data[~split]\n",
        "\n",
        "# summarize split\n",
        "print('Train data rows = %d, columns = %d' % (train.shape[0], train.shape[1]))\n",
        "print('Validation data rows = %d, columns = %d' % (valid.shape[0], valid.shape[1]))\n",
        "\n",
        "# benchmark - Train data rows = 112253, columns = 23\n",
        "# benchmark - Validation data rows = 48085, columns = 23"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5w35fYiCbke",
        "outputId": "d861cfcc-d8aa-48a9-db6d-0ed01cb7b6f6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data rows = 112253, columns = 23\n",
            "Validation data rows = 48085, columns = 23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explainable Boosting Machine"
      ],
      "metadata": {
        "id": "Hl0Kvl6VCdB2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit EBM with random grid search"
      ],
      "metadata": {
        "id": "rW-LYYonCj_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dictionary of hyperparameter value lists for grid search\n",
        "gs_params = {'max_bins': [128, 256, 512],\n",
        "             'max_interaction_bins': [16, 32, 64],\n",
        "             'interactions': [5, 10, 15],\n",
        "             'outer_bags': [4, 8, 12], \n",
        "             'inner_bags': [0, 4],\n",
        "             'learning_rate': [0.001, 0.01, 0.05],\n",
        "             'validation_size': [0.1, 0.25, 0.5],\n",
        "             'min_samples_leaf': [1, 2, 5, 10],\n",
        "             'max_leaves': [1, 3, 5]}\n",
        "\n",
        "# start local timer\n",
        "ebm_tic = time.time()\n",
        "\n",
        "# EBM grid search\n",
        "best_ebm, ebm_grid_frame = ebm_grid(train, valid, x_names, y_name, gs_params=gs_params, n_models=10, \n",
        "                                    early_stopping_rounds=100, seed=SEED)\n",
        "\n",
        "# end local timer\n",
        "ebm_toc = time.time() - ebm_tic\n",
        "print('EBM training completed in %.2f s.' % (ebm_toc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__SeqlXRCpQB",
        "outputId": "74b789c1-a4b3-46b3-fed6-9d07d11ea1ad"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid search run 1/10:\n",
            "Training with parameters: {'n_jobs': 4, 'early_stopping_rounds': 100, 'random_state': 12345, 'max_bins': 512, 'max_interaction_bins': 16, 'interactions': 5, 'outer_bags': 4, 'inner_bags': 0, 'learning_rate': 0.05, 'validation_size': 0.25, 'min_samples_leaf': 1, 'max_leaves': 3}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-1bf56b7a0729>:88: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  ebm_grid_frame = ebm_grid_frame.append(row_dict, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid search new best score discovered at iteration 1/10: 0.8218.\n",
            "---------- ----------\n",
            "Grid search run 2/10:\n",
            "Training with parameters: {'n_jobs': 4, 'early_stopping_rounds': 100, 'random_state': 12345, 'max_bins': 128, 'max_interaction_bins': 32, 'interactions': 5, 'outer_bags': 8, 'inner_bags': 0, 'learning_rate': 0.001, 'validation_size': 0.25, 'min_samples_leaf': 2, 'max_leaves': 5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-1bf56b7a0729>:88: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  ebm_grid_frame = ebm_grid_frame.append(row_dict, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- ----------\n",
            "Grid search run 3/10:\n",
            "Training with parameters: {'n_jobs': 4, 'early_stopping_rounds': 100, 'random_state': 12345, 'max_bins': 512, 'max_interaction_bins': 16, 'interactions': 5, 'outer_bags': 4, 'inner_bags': 0, 'learning_rate': 0.001, 'validation_size': 0.5, 'min_samples_leaf': 1, 'max_leaves': 3}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-1bf56b7a0729>:88: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  ebm_grid_frame = ebm_grid_frame.append(row_dict, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- ----------\n",
            "Grid search run 4/10:\n",
            "Training with parameters: {'n_jobs': 4, 'early_stopping_rounds': 100, 'random_state': 12345, 'max_bins': 128, 'max_interaction_bins': 64, 'interactions': 5, 'outer_bags': 4, 'inner_bags': 4, 'learning_rate': 0.05, 'validation_size': 0.5, 'min_samples_leaf': 1, 'max_leaves': 5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-1bf56b7a0729>:88: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  ebm_grid_frame = ebm_grid_frame.append(row_dict, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- ----------\n",
            "Grid search run 5/10:\n",
            "Training with parameters: {'n_jobs': 4, 'early_stopping_rounds': 100, 'random_state': 12345, 'max_bins': 512, 'max_interaction_bins': 64, 'interactions': 15, 'outer_bags': 4, 'inner_bags': 0, 'learning_rate': 0.05, 'validation_size': 0.1, 'min_samples_leaf': 10, 'max_leaves': 3}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-1bf56b7a0729>:88: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  ebm_grid_frame = ebm_grid_frame.append(row_dict, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid search new best score discovered at iteration 5/10: 0.8253.\n",
            "---------- ----------\n",
            "Grid search run 6/10:\n",
            "Training with parameters: {'n_jobs': 4, 'early_stopping_rounds': 100, 'random_state': 12345, 'max_bins': 256, 'max_interaction_bins': 16, 'interactions': 15, 'outer_bags': 12, 'inner_bags': 4, 'learning_rate': 0.01, 'validation_size': 0.1, 'min_samples_leaf': 2, 'max_leaves': 5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-1bf56b7a0729>:88: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  ebm_grid_frame = ebm_grid_frame.append(row_dict, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- ----------\n",
            "Grid search run 7/10:\n",
            "Training with parameters: {'n_jobs': 4, 'early_stopping_rounds': 100, 'random_state': 12345, 'max_bins': 512, 'max_interaction_bins': 32, 'interactions': 15, 'outer_bags': 4, 'inner_bags': 4, 'learning_rate': 0.05, 'validation_size': 0.25, 'min_samples_leaf': 10, 'max_leaves': 1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-1bf56b7a0729>:88: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  ebm_grid_frame = ebm_grid_frame.append(row_dict, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- ----------\n",
            "Grid search run 8/10:\n",
            "Training with parameters: {'n_jobs': 4, 'early_stopping_rounds': 100, 'random_state': 12345, 'max_bins': 256, 'max_interaction_bins': 16, 'interactions': 15, 'outer_bags': 8, 'inner_bags': 4, 'learning_rate': 0.001, 'validation_size': 0.5, 'min_samples_leaf': 5, 'max_leaves': 3}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-1bf56b7a0729>:88: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  ebm_grid_frame = ebm_grid_frame.append(row_dict, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- ----------\n",
            "Grid search run 9/10:\n",
            "Training with parameters: {'n_jobs': 4, 'early_stopping_rounds': 100, 'random_state': 12345, 'max_bins': 256, 'max_interaction_bins': 16, 'interactions': 10, 'outer_bags': 8, 'inner_bags': 0, 'learning_rate': 0.05, 'validation_size': 0.5, 'min_samples_leaf': 5, 'max_leaves': 1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-1bf56b7a0729>:88: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  ebm_grid_frame = ebm_grid_frame.append(row_dict, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- ----------\n",
            "Grid search run 10/10:\n",
            "Training with parameters: {'n_jobs': 4, 'early_stopping_rounds': 100, 'random_state': 12345, 'max_bins': 512, 'max_interaction_bins': 64, 'interactions': 5, 'outer_bags': 4, 'inner_bags': 0, 'learning_rate': 0.001, 'validation_size': 0.25, 'min_samples_leaf': 2, 'max_leaves': 3}\n",
            "---------- ----------\n",
            "EBM training completed in 1942.05 s.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-1bf56b7a0729>:88: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  ebm_grid_frame = ebm_grid_frame.append(row_dict, ignore_index=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic AUC assessment"
      ],
      "metadata": {
        "id": "5vpEgHf3KNq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_ebm_perf = ROC(best_ebm.predict_proba).explain_perf(valid[x_names], valid[y_name])\n",
        "print('Validation AUC: %.4f.' % best_ebm_perf._internal_obj['overall']['auc'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfcsm0hcKRNO",
        "outputId": "113e412c-26c1-41fc-faa6-502181544d32"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation AUC: 0.8253.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Score validation data with model\n"
      ],
      "metadata": {
        "id": "Za1FIz7DKVuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_ebm_phat = pd.DataFrame(best_ebm.predict_proba(valid[x_names])[:, 1], columns=['phat']) \n",
        "best_ebm_phat = pd.concat([valid.reset_index(drop=True), best_ebm_phat], axis=1)\n",
        "best_ebm_phat.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "3k9Nu4NUKa4l",
        "outputId": "03de93c3-bad2-483f-e43e-3d018b2a2a86"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   row_id  black  asian  white  amind  hipac  hispanic  non_hispanic  male  \\\n",
              "0       0    NaN    NaN    NaN    NaN    NaN       NaN           NaN   1.0   \n",
              "1       6    0.0    0.0    1.0    0.0    0.0       0.0           1.0   0.0   \n",
              "2       8    0.0    0.0    1.0    0.0    0.0       0.0           1.0   NaN   \n",
              "3      10    0.0    0.0    1.0    0.0    0.0       0.0           1.0   NaN   \n",
              "4      11    0.0    0.0    1.0    0.0    0.0       1.0           0.0   NaN   \n",
              "\n",
              "   female  ...  debt_to_income_ratio_missing  loan_amount_std  \\\n",
              "0     0.0  ...                             0        -0.514393   \n",
              "1     1.0  ...                             0        -0.426448   \n",
              "2     NaN  ...                             0         0.277109   \n",
              "3     NaN  ...                             0        -0.382476   \n",
              "4     NaN  ...                             0         0.101220   \n",
              "\n",
              "   loan_to_value_ratio_std  no_intro_rate_period_std  intro_rate_period_std  \\\n",
              "0                 0.333922                  0.244394              -0.215304   \n",
              "1                 0.355249                  0.244394              -0.215304   \n",
              "2                 0.142995                  0.244394              -0.215304   \n",
              "3                -0.240432                  0.244394              -0.215304   \n",
              "4                -0.266529                  0.244394              -0.215304   \n",
              "\n",
              "   property_value_std  income_std  debt_to_income_ratio_std  high_priced  \\\n",
              "0           -0.535932   -0.040307                  0.854601            0   \n",
              "1           -0.474263   -0.020904                  1.037419            0   \n",
              "2            0.111598   -0.019865                  0.031916            0   \n",
              "3           -0.320089   -0.028181                  0.946010            0   \n",
              "4            0.111598    0.016515                 -1.156406            0   \n",
              "\n",
              "       phat  \n",
              "0  0.165646  \n",
              "1  0.314594  \n",
              "2  0.022284  \n",
              "3  0.015600  \n",
              "4  0.004888  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-823d72e4-2841-4f11-a501-e1e4bd482382\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_id</th>\n",
              "      <th>black</th>\n",
              "      <th>asian</th>\n",
              "      <th>white</th>\n",
              "      <th>amind</th>\n",
              "      <th>hipac</th>\n",
              "      <th>hispanic</th>\n",
              "      <th>non_hispanic</th>\n",
              "      <th>male</th>\n",
              "      <th>female</th>\n",
              "      <th>...</th>\n",
              "      <th>debt_to_income_ratio_missing</th>\n",
              "      <th>loan_amount_std</th>\n",
              "      <th>loan_to_value_ratio_std</th>\n",
              "      <th>no_intro_rate_period_std</th>\n",
              "      <th>intro_rate_period_std</th>\n",
              "      <th>property_value_std</th>\n",
              "      <th>income_std</th>\n",
              "      <th>debt_to_income_ratio_std</th>\n",
              "      <th>high_priced</th>\n",
              "      <th>phat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.514393</td>\n",
              "      <td>0.333922</td>\n",
              "      <td>0.244394</td>\n",
              "      <td>-0.215304</td>\n",
              "      <td>-0.535932</td>\n",
              "      <td>-0.040307</td>\n",
              "      <td>0.854601</td>\n",
              "      <td>0</td>\n",
              "      <td>0.165646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.426448</td>\n",
              "      <td>0.355249</td>\n",
              "      <td>0.244394</td>\n",
              "      <td>-0.215304</td>\n",
              "      <td>-0.474263</td>\n",
              "      <td>-0.020904</td>\n",
              "      <td>1.037419</td>\n",
              "      <td>0</td>\n",
              "      <td>0.314594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.277109</td>\n",
              "      <td>0.142995</td>\n",
              "      <td>0.244394</td>\n",
              "      <td>-0.215304</td>\n",
              "      <td>0.111598</td>\n",
              "      <td>-0.019865</td>\n",
              "      <td>0.031916</td>\n",
              "      <td>0</td>\n",
              "      <td>0.022284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.382476</td>\n",
              "      <td>-0.240432</td>\n",
              "      <td>0.244394</td>\n",
              "      <td>-0.215304</td>\n",
              "      <td>-0.320089</td>\n",
              "      <td>-0.028181</td>\n",
              "      <td>0.946010</td>\n",
              "      <td>0</td>\n",
              "      <td>0.015600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.101220</td>\n",
              "      <td>-0.266529</td>\n",
              "      <td>0.244394</td>\n",
              "      <td>-0.215304</td>\n",
              "      <td>0.111598</td>\n",
              "      <td>0.016515</td>\n",
              "      <td>-1.156406</td>\n",
              "      <td>0</td>\n",
              "      <td>0.004888</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-823d72e4-2841-4f11-a501-e1e4bd482382')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-823d72e4-2841-4f11-a501-e1e4bd482382 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-823d72e4-2841-4f11-a501-e1e4bd482382');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Investigate Best Model (EBM) for Discrimination"
      ],
      "metadata": {
        "id": "rfhBmn27KfiO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find optimal cutoff based on F1"
      ],
      "metadata": {
        "id": "nbQUpF3MKixU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Cutoffs are normally selected by maximizing a quality statistic or a business metric, and not by considering bias and discrimination."
      ],
      "metadata": {
        "id": "Enrtg4HOKmhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f1_frame = get_max_f1_frame(best_ebm_phat, y_name, 'phat')\n",
        "\n",
        "print(f1_frame)\n",
        "print()\n",
        "\n",
        "max_f1 = f1_frame['f1'].max()\n",
        "best_cut = f1_frame.loc[int(f1_frame['f1'].idxmax()), 'cut'] #idxmax() returns the index of the maximum value\n",
        "acc = f1_frame.loc[int(f1_frame['f1'].idxmax()), 'acc']\n",
        "\n",
        "print('Best EBM F1: %.4f achieved at cutoff: %.2f with accuracy: %.4f.' % (max_f1, best_cut, acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A34vfdq9KpX6",
        "outputId": "94e8ad14-49c4-4f3e-de0d-6cd3c1612e6f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      cut        f1       acc\n",
            "0    0.00  0.173860  0.095206\n",
            "1    0.01  0.233938  0.384777\n",
            "2    0.02  0.262541  0.479048\n",
            "3    0.03  0.280733  0.530685\n",
            "4    0.04  0.295953  0.569783\n",
            "..    ...       ...       ...\n",
            "96   0.96  0.000000  0.904794\n",
            "97   0.97  0.000000  0.904794\n",
            "98   0.98  0.000000  0.904794\n",
            "99   0.99  0.000000  0.904794\n",
            "100  1.00  0.000000  0.904794\n",
            "\n",
            "[101 rows x 3 columns]\n",
            "\n",
            "Best EBM F1: 0.3666 achieved at cutoff: 0.18 with accuracy: 0.7927.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n",
            "<ipython-input-23-4847137f7901>:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  f1_frame = f1_frame.append(row_dict, ignore_index=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find confusion matrices for demographic groups"
      ],
      "metadata": {
        "id": "m3CzpdXmKtxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "demographic_group_names = ['black', 'asian', 'white', 'male', 'female']\n",
        "cm_dict = {}\n",
        "\n",
        "for name in demographic_group_names:\n",
        "    cm_dict[name] = get_confusion_matrix(best_ebm_phat, y_name, 'phat', by=name, level=1, cutoff=best_cut)\n",
        "    print(cm_dict[name])\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSTTmZP3K1a5",
        "outputId": "5025c346-3e03-460f-8384-986531b72e88"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix by black=1\n",
            "             actual: 1 actual: 0\n",
            "predicted: 1       470       911\n",
            "predicted: 0       194      1617\n",
            "\n",
            "Confusion matrix by asian=1\n",
            "             actual: 1 actual: 0\n",
            "predicted: 1        95       176\n",
            "predicted: 0        53      2926\n",
            "\n",
            "Confusion matrix by white=1\n",
            "             actual: 1 actual: 0\n",
            "predicted: 1      1965      6117\n",
            "predicted: 0      1200     25243\n",
            "\n",
            "Confusion matrix by male=1\n",
            "             actual: 1 actual: 0\n",
            "predicted: 1      1036      3122\n",
            "predicted: 0       628     11046\n",
            "\n",
            "Confusion matrix by female=1\n",
            "             actual: 1 actual: 0\n",
            "predicted: 1       847      2175\n",
            "predicted: 0       393      6617\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find AIR for Asian people"
      ],
      "metadata": {
        "id": "ckPABH3VK5Cp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Adverse impact ratio for Asian people vs. White people: %.3f' % air(cm_dict, 'white', 'asian'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFI0AxPOK7im",
        "outputId": "a0f892b0-b107-4ce4-9543-f086b373d210"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "White proportion accepted: 0.766\n",
            "Asian proportion accepted: 0.917\n",
            "Adverse impact ratio for Asian people vs. White people: 1.197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find AIR for Black people"
      ],
      "metadata": {
        "id": "oP02ZEsGM-EW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Adverse impact ratio for Black people vs. White people: %.3f' % air(cm_dict, 'white', 'black'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XR9VfRjPNC8h",
        "outputId": "18e78295-4aed-4035-a317-9a8b9c7a20d4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "White proportion accepted: 0.766\n",
            "Black proportion accepted: 0.567\n",
            "Adverse impact ratio for Black people vs. White people: 0.741\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find AIR for Females"
      ],
      "metadata": {
        "id": "xZTg-jDoNGpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Adverse impact ratio for Females vs. Males: %.3f' % air(cm_dict, 'male', 'female'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKNv9I_yNJoC",
        "outputId": "9c3979e7-3f5e-49d5-a19d-3bf84aafa082"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Male proportion accepted: 0.737\n",
            "Female proportion accepted: 0.699\n",
            "Adverse impact ratio for Females vs. Males: 0.948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attempt remediation of discovered discrimination"
      ],
      "metadata": {
        "id": "VsqnOUghNNAG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simplest remediation: Find cutoff with better Black vs. White AIR"
      ],
      "metadata": {
        "id": "ZWSle2pyNQSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f1_frame = get_max_f1_frame(best_ebm_phat, y_name, 'phat', air_reference='white', air_protected='black')\n",
        "# print highest quality cutoffs above four fifths rule cutoff\n",
        "f1_frame[f1_frame['air'] > 0.8].sort_values(by='f1', ascending=False).head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bU2Y0IQlNTJ1",
        "outputId": "8c8fee50-25c7-41a0-fb37-64e3191067e0"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     cut        f1       acc       air\n",
              "22  0.22  0.356794  0.832942  0.816260\n",
              "23  0.23  0.350179  0.841156  0.843019\n",
              "24  0.24  0.341709  0.850161  0.864101\n",
              "25  0.25  0.330154  0.858313  0.878680\n",
              "26  0.26  0.316466  0.865155  0.887407"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3d72097a-2fce-45b1-879a-1ddaa1f5969a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cut</th>\n",
              "      <th>f1</th>\n",
              "      <th>acc</th>\n",
              "      <th>air</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.22</td>\n",
              "      <td>0.356794</td>\n",
              "      <td>0.832942</td>\n",
              "      <td>0.816260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.23</td>\n",
              "      <td>0.350179</td>\n",
              "      <td>0.841156</td>\n",
              "      <td>0.843019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.24</td>\n",
              "      <td>0.341709</td>\n",
              "      <td>0.850161</td>\n",
              "      <td>0.864101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.25</td>\n",
              "      <td>0.330154</td>\n",
              "      <td>0.858313</td>\n",
              "      <td>0.878680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.26</td>\n",
              "      <td>0.316466</td>\n",
              "      <td>0.865155</td>\n",
              "      <td>0.887407</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d72097a-2fce-45b1-879a-1ddaa1f5969a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3d72097a-2fce-45b1-879a-1ddaa1f5969a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3d72097a-2fce-45b1-879a-1ddaa1f5969a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Cutoffs in the 0.22-0.26 range provide increased accuracy and less bias towards Black people."
      ],
      "metadata": {
        "id": "kBNoES8LNpbo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check that other groups are not adversely impacted by change"
      ],
      "metadata": {
        "id": "aMFmyWeeNuIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate new confusion matrics for each group\n",
        "rem_cm_dict = {}\n",
        "for name in demographic_group_names:\n",
        "    rem_cm_dict[name] = get_confusion_matrix(best_ebm_phat, y_name, 'phat', by=name, level=1, cutoff=0.22, verbose=False)\n",
        "\n",
        "# calculate AIR for each group\n",
        "print('Adverse impact ratio for Asian people vs. White people: %.3f' % air(rem_cm_dict, 'white', 'asian', verbose=False))\n",
        "print('Adverse impact ratio for Black people vs. White people: %.3f' % air(rem_cm_dict, 'white', 'black', verbose=False))\n",
        "print('Adverse impact ratio for Females vs. Males: %.3f' % air(rem_cm_dict, 'male', 'female', verbose=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jPSXAauNtM9",
        "outputId": "f6c66ee8-0979-483b-89e7-0175b151877b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adverse impact ratio for Asian people vs. White people: 1.128\n",
            "Adverse impact ratio for Black people vs. White people: 0.816\n",
            "Adverse impact ratio for Females vs. Males: 0.965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### The new cutoff does not adversely affect other protected groups."
      ],
      "metadata": {
        "id": "OKx0dDUjN0AR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### More sophisticated remediation: Model selection via quality and fairness"
      ],
      "metadata": {
        "id": "dJfmto3jN586"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# start local timer\n",
        "ebm2_tic = time.time()\n",
        "\n",
        "# new grid search that also considers AIR and fairness\n",
        "best_ebm2, ebm_grid_frame = ebm_grid(train, best_ebm_phat, x_names, y_name, gs_params=gs_params, n_models=500, \n",
        "                                     early_stopping_rounds=100, seed=SEED, air_reference='white', air_protected='black', \n",
        "                                     air_cut=0.17)\n",
        "\n",
        "# end local timer\n",
        "ebm2_toc = time.time() - ebm2_tic\n",
        "print('EBM training completed in %.2f s.' % (ebm2_toc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "kG8eBkUeN3gw",
        "outputId": "443e0880-aae6-4fce-a9af-a94d64c38614"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7a92f4d7496c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# start local timer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mebm2_tic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# new grid search that also considers AIR and fairness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m best_ebm2, ebm_grid_frame = ebm_grid(train, best_ebm_phat, x_names, y_name, gs_params=gs_params, n_models=500, \n",
            "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Display grid search results as table"
      ],
      "metadata": {
        "id": "-t0aTPYUSJhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ebm_grid_frame"
      ],
      "metadata": {
        "id": "rqA0ujSbXpIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Display grid search results as plot"
      ],
      "metadata": {
        "id": "1z-QOTTwXqrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(8,8))\n",
        "_ = ebm_grid_frame.plot(kind='scatter', x='air', y='auc', title='AIR vs. AUC for EBMs', ax=ax)\n",
        "_ = ax.axvline(x=0.8, color='r', linestyle='--')\n",
        "_ = ax.set_ylim([0.4, 0.85])\n",
        "_ = ax.set_xlim([0.75, 1.05])\n",
        "_ = ax.set_xlabel('AIR')\n",
        "_ = ax.set_ylabel('AUC')"
      ],
      "metadata": {
        "id": "laQQgXU_XuwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrain most accurate model above 0.8 AIR"
      ],
      "metadata": {
        "id": "bVDSeXS2Xx2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extract new params dict from ebm_grid_frame\n",
        "rem_params = ebm_grid_frame.loc[ebm_grid_frame['air'] > 0.8].sort_values(by='auc', ascending=False).iloc[0, :].to_dict()\n",
        "\n",
        "# extract features from dict then delete from dict \n",
        "rem_x_names = rem_params['features']\n",
        "del rem_params['features']\n",
        "\n",
        "# record and delete other extraneous information\n",
        "print('Best AUC: %.4f above 0.8 AIR (%.4f).' % (rem_params['auc'], rem_params['air']))\n",
        "del rem_params['auc']\n",
        "del rem_params['air']\n",
        "\n",
        "# reset some parameters to integers\n",
        "rem_params['random_state'] = int(rem_params['random_state'])\n",
        "rem_params['n_jobs'] = int(rem_params['n_jobs'])\n",
        "\n",
        "# retrain\n",
        "rem_ebm = ExplainableBoostingClassifier(**rem_params)\n",
        "rem_ebm.fit(train[rem_x_names], train[y_name]) \n",
        "rem_ebm_perf = ROC(rem_ebm.predict_proba).explain_perf(valid[rem_x_names], valid[y_name])\n",
        "rem_auc = rem_ebm_perf._internal_obj['overall']['auc']\n",
        "print('Remediated EBM retrained with AUC: %.4f.' % rem_auc)"
      ],
      "metadata": {
        "id": "FmTd0AScX0z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check that other groups are not adversely impacted by change"
      ],
      "metadata": {
        "id": "I4JHJof7X3I0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a frame with remediated EBM predictions\n",
        "best_ebm_phat2 = pd.DataFrame(rem_ebm.predict_proba(valid[rem_x_names])[:, 1], columns=['phat']) \n",
        "best_ebm_phat2 = pd.concat([valid.reset_index(drop=True), best_ebm_phat2], axis=1)\n",
        "\n",
        "# calculate new confusion matrices for each group\n",
        "rem_cm_dict2 = {}\n",
        "for name in demographic_group_names:\n",
        "    rem_cm_dict2[name] = get_confusion_matrix(best_ebm_phat2, y_name, 'phat', by=name, level=1, cutoff=0.17, verbose=False)\n",
        "\n",
        "# calculate AIR for each group\n",
        "print('Adverse impact ratio for Asian people vs. White people: %.3f' % air(rem_cm_dict2, 'white', 'asian', verbose=False))\n",
        "print('Adverse impact ratio for Black people vs. White people: %.3f' % air(rem_cm_dict2, 'white', 'black', verbose=False))\n",
        "print('Adverse impact ratio for Females vs. Males: %.3f' % air(rem_cm_dict2, 'male', 'female', verbose=False))"
      ],
      "metadata": {
        "id": "0XJsFXQsZBd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### This analysis shows that even with a selective cutoff of 0.17, less discriminatory models are available. The new set of features and hyperparameters leads to a ~13% increase in AIR with a ~5% decrease in AUC."
      ],
      "metadata": {
        "id": "fZo7DjigZEv_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Print best model parameters for later use"
      ],
      "metadata": {
        "id": "UNopGJjhZgzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rem_params"
      ],
      "metadata": {
        "id": "NJxGPIvIZj7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Print best model features for later use"
      ],
      "metadata": {
        "id": "pKDgh7HzZkjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rem_x_names"
      ],
      "metadata": {
        "id": "GuNPAK6OZof1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## New model score files "
      ],
      "metadata": {
        "id": "dChw67stZ0r7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Assign new modelling roles"
      ],
      "metadata": {
        "id": "oJ5rqcRUaBOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_name = 'high_priced'\n",
        "x_names = []\n",
        "     "
      ],
      "metadata": {
        "id": "RRk6KDD5Z46N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit interpretable models"
      ],
      "metadata": {
        "id": "v1qL9IGIaQ1g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Split data into train and validation partitions"
      ],
      "metadata": {
        "id": "W3DDvktyaT8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(SEED) # preserve exact reproducibility for this cell\n",
        "\n",
        "split_ratio = 0.7 # 70%/30% train/test split\n",
        "\n",
        "# execute split\n",
        "split = np.random.rand(len(data)) < split_ratio\n",
        "train = data[split]\n",
        "valid = data[~split]\n",
        "\n",
        "# summarize split\n",
        "print('Train data rows = %d, columns = %d' % (train.shape[0], train.shape[1]))\n",
        "print('Validation data rows = %d, columns = %d' % (valid.shape[0], valid.shape[1]))\n",
        "\n",
        "# benchmark - Train data rows = 112253, columns = 23\n",
        "# benchmark - Validation data rows = 48085, columns = 23"
      ],
      "metadata": {
        "id": "kwnFrAeoaX2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Elastic Net "
      ],
      "metadata": {
        "id": "48AkaKosmHBn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Define wrapper function for grid search"
      ],
      "metadata": {
        "id": "zfGKUVm4mJe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def glm_grid(x_names, y_name, htrain, hvalid, seed):\n",
        "\n",
        "    \"\"\" Wrapper function for penalized GLM with alpha and lambda search.\n",
        "\n",
        "    :param x_names: Names of input features.\n",
        "    :param y_name: Name of target feature.\n",
        "    :param htrain: Training H2OFrame.\n",
        "    :param hvalid: Validation H2OFrame.\n",
        "    :param seed: Random seed for better reproducibility.\n",
        "    :return: Best H2OGeneralizedLinearEstimator.\n",
        "    \"\"\"\n",
        "\n",
        "    alpha_opts = [0.01, 0.25, 0.5, 0.99]  # always keep some L2\n",
        "\n",
        "    # define search criteria\n",
        "    # i.e., over alpha\n",
        "    # lamda search handled by lambda_search param below\n",
        "    hyper_parameters = {'alpha': alpha_opts}\n",
        "\n",
        "    # initialize grid search\n",
        "    grid = H2OGridSearch(\n",
        "        H2OGeneralizedLinearEstimator(family='binomial',\n",
        "                                      lambda_search=True,\n",
        "                                      seed=seed), # seed for grid search\n",
        "        hyper_params=hyper_parameters)\n",
        "\n",
        "   \n",
        "    grid.train(y=y_name,\n",
        "               x=x_names,\n",
        "               training_frame=htrain,\n",
        "               validation_frame=hvalid,\n",
        "               seed=seed) # seed for training\n",
        "\n",
        "    # select best model from grid search\n",
        "    best_model = grid.get_grid()[0]\n",
        "    del grid\n",
        "\n",
        "    return best_model\n",
        "     "
      ],
      "metadata": {
        "id": "5aUyZQm-mN1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Fit elastic net with grid search"
      ],
      "metadata": {
        "id": "KBE63BVCmRWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# start local timer\n",
        "glm_tic = time.time()\n",
        "\n",
        "# convert data to h2o frames\n",
        "htrain = h2o.H2OFrame(train)\n",
        "hvalid = h2o.H2OFrame(valid)\n",
        "\n",
        "# train with grid search\n",
        "\n",
        "\n",
        "best_glm = glm_grid(x_names, y_name, htrain, hvalid, SEED)\n",
        "\n",
        "# end local timer\n",
        "glm_toc = time.time() - glm_tic\n",
        "print('Elastic net GLM training completed in %.2f s.' % (glm_toc))"
      ],
      "metadata": {
        "id": "g0DWzl1YmWfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Basic AUC assessment "
      ],
      "metadata": {
        "id": "atZ1IfiDnJiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Validation AUC: %.4f.' % best_glm.auc(valid=True))"
      ],
      "metadata": {
        "id": "eUFTDGd_nNgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Write submission file "
      ],
      "metadata": {
        "id": "JkAWXuuWnP6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_glm_submit = best_glm.predict(h2o.H2OFrame(test)).as_data_frame() \n",
        "best_glm_submit.drop(['predict', 'p0'], axis=1, inplace=True)\n",
        "best_glm_submit.columns = ['phat']\n",
        "best_glm_submit.to_csv('group1_best_glm_' + '.csv')"
      ],
      "metadata": {
        "id": "AeEGyw_8nUKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('group1_best_glm_.csv')\n",
        "     "
      ],
      "metadata": {
        "id": "n9Cgy46hnXI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Monotonic XGBoost"
      ],
      "metadata": {
        "id": "UGQ7KBCPoYln"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Define utility function for random grid search"
      ],
      "metadata": {
        "id": "J1W-DZ82oZDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def xgb_grid(dtrain, dvalid, mono_constraints=None, gs_params=None, n_models=None,\n",
        "             ntree=None, early_stopping_rounds=None, verbose=False, seed=None):\n",
        "    \n",
        "    \"\"\" Performs a random grid search over n_models and gs_params.\n",
        "\n",
        "    :param dtrain: Training data in LightSVM format.\n",
        "    :param dvalid: Validation data in LightSVM format.\n",
        "    :param mono_constraints: User-supplied monotonicity constraints.\n",
        "    :param gs_params: Dictionary of lists of potential XGBoost parameters over which to search.\n",
        "    :param n_models: Number of random models to evaluate.\n",
        "    :param ntree: Number of trees in XGBoost model.\n",
        "    :param early_stopping_rounds: XGBoost early stopping rounds.\n",
        "    :param verbose: Whether to display training iterations, default False.\n",
        "    :param seed: Random seed for better interpretability.\n",
        "    :return: Best candidate model from random grid search.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # cartesian product of gs_params\n",
        "    keys, values = zip(*gs_params.items())\n",
        "    experiments = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
        "\n",
        "    # preserve exact reproducibility for this function\n",
        "    np.random.seed(SEED) \n",
        "    \n",
        "    # select randomly from cartesian product space\n",
        "    selected_experiments = np.random.choice(len(experiments), n_models)\n",
        "\n",
        "    # set global params for objective,  etc.\n",
        "    params = {'booster': 'gbtree',\n",
        "              'eval_metric': 'auc',\n",
        "              'nthread': NTHREAD,\n",
        "              'objective': 'binary:logistic',\n",
        "              'seed': SEED}\n",
        "\n",
        "    # init grid search loop\n",
        "    best_candidate = None\n",
        "    best_score = 0\n",
        "\n",
        "    # grid search loop\n",
        "    for i, exp in enumerate(selected_experiments):\n",
        "\n",
        "        params.update(experiments[exp])  # override global params with current grid run params\n",
        "\n",
        "        print('Grid search run %d/%d:' % (int(i + 1), int(n_models)))\n",
        "        print('Training with parameters:', params)\n",
        "\n",
        "        # train on current params\n",
        "        watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
        "        \n",
        "        if mono_constraints is not None:\n",
        "            params['monotone_constraints'] = mono_constraints\n",
        "        \n",
        "        candidate = xgb.train(params,\n",
        "                              dtrain,\n",
        "                              ntree,\n",
        "                              early_stopping_rounds=early_stopping_rounds,\n",
        "                              evals=watchlist,\n",
        "                              verbose_eval=verbose)    \n",
        "\n",
        "        # determine if current model is better than previous best\n",
        "        if candidate.best_score > best_score:\n",
        "            best_candidate = candidate\n",
        "            best_score = candidate.best_score\n",
        "            print('Grid search new best score discovered at iteration %d/%d: %.4f.' %\n",
        "                             (int(i + 1), int(n_models), candidate.best_score))\n",
        "\n",
        "        print('---------- ----------')\n",
        "            \n",
        "    return best_candidate"
      ],
      "metadata": {
        "id": "xBGu9kd3olwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Fit monotonic XGBoost with random grid search"
      ],
      "metadata": {
        "id": "214s8sfVozoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dictionary of hyperparameter value lists for grid search\n",
        "gs_params = {'colsample_bytree': [0.3, 0.5, 0.7, 0.9],\n",
        "             'colsample_bylevel': [0.3, 0.5, 0.7, 0.9],\n",
        "             'eta': [0.005, 0.05, 0.5],\n",
        "             'max_depth': [3, 5, 7],\n",
        "             'reg_alpha': [0.0005, 0.005, 0.05],\n",
        "             'reg_lambda': [0.0005, 0.005, 0.05],\n",
        "             'subsample': [0.3, 0.5, 0.7, 0.9],\n",
        "             'min_child_weight': [1, 5, 10], \n",
        "             'gamma': [0.0, 0.1, 0.2 , 0.3, 0.4]}\n",
        "\n",
        "# define monotonicity constraints\n",
        "mono_constraints = tuple([int(i) for i in np.sign(train[x_names + [y_name]].corr()[y_name].values[:-1])])\n",
        "\n",
        "# start local timer\n",
        "mxgb_tic = time.time()\n",
        "\n",
        "# Convert data to SVMLight format\n",
        "dtrain = xgb.DMatrix(train[x_names], train[y_name])\n",
        "dvalid = xgb.DMatrix(valid[x_names], valid[y_name])\n",
        "\n",
        "# Monotonic XGBoost grid search\n",
        "best_mxgb = xgb_grid(dtrain, dvalid, gs_params=gs_params, n_models=50, ntree=1000, early_stopping_rounds=100, \n",
        "                     mono_constraints=mono_constraints, seed=SEED)\n",
        "\n",
        "# end local timer\n",
        "mxgb_toc = time.time() - mxgb_tic\n",
        "print('Monotonic GBM training completed in %.2f s.' % (mxgb_toc))"
      ],
      "metadata": {
        "id": "tR52KtlJo4rH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Basic AUC assessment"
      ],
      "metadata": {
        "id": "bCJ_i0J8pBsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Validation AUC: %.4f.' % best_mxgb.best_score)"
      ],
      "metadata": {
        "id": "Ij0SJTvhpE0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Write submission file "
      ],
      "metadata": {
        "id": "5yUlYSTqpG6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dtest = xgb.DMatrix(test[x_names])\n",
        "best_mxgb_submit = pd.DataFrame(best_mxgb.predict(dtest, iteration_range=(0, best_mxgb.best_ntree_limit)), columns=['phat'])\n",
        "best_mxgb_submit.to_csv('group1_best_mxgb_.csv',index=False)\n",
        "     "
      ],
      "metadata": {
        "id": "JBe9kXAjpLaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "files.download('group1_best_mxgb_.csv')\n"
      ],
      "metadata": {
        "id": "A9DBDUjVpNmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explainable Boosting Machine "
      ],
      "metadata": {
        "id": "nzFWQJYfpPsZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Define utility function for random grid search\n",
        "\n"
      ],
      "metadata": {
        "id": "zLKTNVQJqWQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ebm_grid(train, valid, x_names, y_name, gs_params=None, n_models=None, early_stopping_rounds=None, seed=None):\n",
        "    \n",
        "    \"\"\" Performs a random grid search over n_models and gs_params.\n",
        "\n",
        "    :param train: Training data as Pandas DataFrame.\n",
        "    :param valid: Validation data as Pandas DataFrame.\n",
        "    :param x_names: Names of input features.\n",
        "    :param y_name: Name of target feature.\n",
        "    :param gs_params: Dictionary of lists of potential EBM parameters over which to search.   \n",
        "    :param n_models: Number of random models to evaluate.\n",
        "    :param early_stopping_rounds: EBM early stopping rounds.\n",
        "    :param seed: Random seed for better interpretability.\n",
        "    :return: Best candidate model from random grid search.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # cartesian product of gs_params\n",
        "    keys, values = zip(*gs_params.items())\n",
        "    experiments = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
        "\n",
        "    # preserve exact reproducibility for this function\n",
        "    np.random.seed(SEED) \n",
        "    \n",
        "    # select randomly from cartesian product space\n",
        "    selected_experiments = np.random.choice(len(experiments), n_models)\n",
        "\n",
        "    # set global params for seed, etc.\n",
        "    params = {'n_jobs': NTHREAD,\n",
        "              'early_stopping_rounds': early_stopping_rounds, \n",
        "              'random_state': SEED}\n",
        "\n",
        "    # init grid search loop\n",
        "    best_candidate = None\n",
        "    best_score = 0\n",
        "\n",
        "    # grid search loop\n",
        "    for i, exp in enumerate(selected_experiments):\n",
        "\n",
        "        params.update(experiments[exp])  # override global params with current grid run params\n",
        "\n",
        "        print('Grid search run %d/%d:' % (int(i + 1), int(n_models)))\n",
        "        print('Training with parameters:', params)\n",
        "        \n",
        "        # train \n",
        "        ebm = ExplainableBoostingClassifier(**params)\n",
        "        candidate = ebm.fit(train[x_names], train[y_name]) \n",
        "        \n",
        "        # calculate AUC\n",
        "        ebm_perf = ROC(ebm.predict_proba).explain_perf(valid[x_names], valid[y_name])\n",
        "        candidate_best_score = ebm_perf._internal_obj['overall']['auc']\n",
        "    \n",
        "        # determine if current model is better than previous best\n",
        "        if candidate_best_score > best_score:\n",
        "            best_candidate = candidate\n",
        "            best_score = candidate_best_score\n",
        "            print('Grid search new best score discovered at iteration %d/%d: %.4f.' %\n",
        "                             (int(i + 1), int(n_models), candidate_best_score))\n",
        "\n",
        "        print('---------- ----------')\n",
        "        \n",
        "        del ebm\n",
        "            \n",
        "    return best_candidate"
      ],
      "metadata": {
        "id": "lokfx4a3qZ11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Fit EBM with random grid search"
      ],
      "metadata": {
        "id": "IKw5CGn2qdcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dictionary of hyperparameter value lists for grid search\n",
        "gs_params = {'max_bins': [128, 256, 512],\n",
        "             'max_interaction_bins': [16, 32, 64],\n",
        "             'interactions': [5, 10, 15],\n",
        "             'outer_bags': [4, 8, 12], \n",
        "             'inner_bags': [0, 4],\n",
        "             'learning_rate': [0.001, 0.01, 0.05],\n",
        "             'validation_size': [0.1, 0.25, 0.5],\n",
        "             'min_samples_leaf': [1, 2, 5, 10],\n",
        "             'max_leaves': [1, 3, 5]}\n",
        "\n",
        "# start local timer\n",
        "ebm_tic = time.time()\n",
        "\n",
        "# EBM grid search\n",
        "best_ebm = ebm_grid(train, valid, x_names, y_name, gs_params=gs_params, n_models=10, \n",
        "                    early_stopping_rounds=100, seed=SEED)\n",
        "\n",
        "# end local timer\n",
        "ebm_toc = time.time() - ebm_tic\n",
        "print('EBM training completed in %.2f s.' % (ebm_toc))"
      ],
      "metadata": {
        "id": "T9Y2kkr5qndS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Basic AUC assessment "
      ],
      "metadata": {
        "id": "CD1tlmOqqrl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_ebm_perf = ROC(best_ebm.predict_proba).explain_perf(valid[x_names], valid[y_name])\n",
        "print('Validation AUC: %.4f.' % best_ebm_perf._internal_obj['overall']['auc'])"
      ],
      "metadata": {
        "id": "uJFrpfrGqvms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Write submission file "
      ],
      "metadata": {
        "id": "y5b9p6hrqypJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_ebm_submit = pd.DataFrame(best_ebm.predict_proba(test[x_names])[:, 1], columns=['phat'])\n",
        "best_ebm_submit.to_csv('group1_best_ebm_.csv',index=False)"
      ],
      "metadata": {
        "id": "cPU2UF8Fq1vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('group1_best_ebm_.csv')"
      ],
      "metadata": {
        "id": "TGDiGBnSq4yS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### End timer"
      ],
      "metadata": {
        "id": "1tTOwYBhZqme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "toc = time.time() - tic\n",
        "print('All tasks completed in %.2f s.' % (toc))"
      ],
      "metadata": {
        "id": "yY1HaCPjZtd2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}